{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Build an image that can do training and inference in SageMaker\r\n",
      "# This is a Python 2 image that uses the nginx, gunicorn, flask stack\r\n",
      "# for serving inferences in a stable way.\r\n",
      "\r\n",
      "FROM ubuntu:16.04\r\n",
      "\r\n",
      "MAINTAINER Amazon AI <sage-learner@amazon.com>\r\n",
      "\r\n",
      "\r\n",
      "RUN apt-get -y update && apt-get install -y --no-install-recommends \\\r\n",
      "         wget \\\r\n",
      "         python \\\r\n",
      "         nginx \\\r\n",
      "         ca-certificates \\\r\n",
      "    && rm -rf /var/lib/apt/lists/*\r\n",
      "\r\n",
      "# Here we get all python packages.\r\n",
      "# There's substantial overlap between scipy and numpy that we eliminate by\r\n",
      "# linking them together. Likewise, pip leaves the install caches populated which uses\r\n",
      "# a significant amount of space. These optimizations save a fair amount of space in the\r\n",
      "# image, which reduces start up time.\r\n",
      "RUN wget https://bootstrap.pypa.io/get-pip.py && python get-pip.py && \\\r\n",
      "    pip install numpy scipy scikit-learn pandas cloudpickle flask gevent gunicorn && \\\r\n",
      "        (cd /usr/local/lib/python2.7/dist-packages/scipy/.libs; rm *; ln ../../numpy/.libs/* .) && \\\r\n",
      "        rm -rf /root/.cache\r\n",
      "\r\n",
      "# Set some environment variables. PYTHONUNBUFFERED keeps Python from buffering our standard\r\n",
      "# output stream, which means that logs can be delivered to the user quickly. PYTHONDONTWRITEBYTECODE\r\n",
      "# keeps Python from writing the .pyc files which are unnecessary in this case. We also update\r\n",
      "# PATH so that the train and serve programs are found when the container is invoked.\r\n",
      "USER root\r\n",
      "\r\n",
      "# Spark dependencies\r\n",
      "ENV APACHE_SPARK_VERSION 2.3.0\r\n",
      "ENV HADOOP_VERSION 2.7\r\n",
      "\r\n",
      "RUN apt-get -y update && \\\r\n",
      "    apt-get install --no-install-recommends -y openjdk-8-jre-headless ca-certificates-java && \\\r\n",
      "    apt-get clean && \\\r\n",
      "    rm -rf /var/lib/apt/lists/*\r\n",
      "RUN cd /tmp && \\\r\n",
      "        wget -q http://apache.claz.org/spark/spark-${APACHE_SPARK_VERSION}/spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz && \\\r\n",
      "        echo \"258683885383480BA01485D6C6F7DC7CFD559C1584D6CEB7A3BBCF484287F7F57272278568F16227BE46B4F92591768BA3D164420D87014A136BF66280508B46 *spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz\" | sha512sum -c - && \\\r\n",
      "        tar xzf spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz -C /usr/local && \\\r\n",
      "        rm spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz\r\n",
      "RUN cd /usr/local && ln -s spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION} spark\r\n",
      "\r\n",
      "ENV SPARK_HOME /usr/local/spark\r\n",
      "ENV PYTHONPATH $SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.6-src.zip\r\n",
      "ENV SPARK_OPTS --driver-java-options=-Xms1024M --driver-java-options=-Xmx4096M --driver-java-options=-Dlog4j.logLevel=info\r\n",
      "\r\n",
      "ENV PYTHONUNBUFFERED=TRUE\r\n",
      "ENV PYTHONDONTWRITEBYTECODE=TRUE\r\n",
      "ENV PATH=\"/opt/program:${PATH}\"\r\n",
      "\r\n",
      "# Set up the program in the image\r\n",
      "COPY alsriaz /opt/program\r\n",
      "\r\n",
      "WORKDIR /opt/program"
     ]
    }
   ],
   "source": [
    "# ### read the DockerFile contants #####\n",
    "!cat container/Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Stopping docker: [  OK  ]\r\n",
      "Starting docker:\t.[  OK  ]\r\n",
      "Sending build context to Docker daemon  39.42kB\r",
      "\r\n",
      "Step 1/18 : FROM ubuntu:16.04\n",
      " ---> f975c5035748\n",
      "Step 2/18 : MAINTAINER Amazon AI <sage-learner@amazon.com>\n",
      " ---> Using cache\n",
      " ---> aeddbc87b01a\n",
      "Step 3/18 : RUN apt-get -y update && apt-get install -y --no-install-recommends          wget          python          nginx          ca-certificates     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> 58028364b3aa\n",
      "Step 4/18 : RUN wget https://bootstrap.pypa.io/get-pip.py && python get-pip.py &&     pip install numpy scipy scikit-learn pandas cloudpickle flask gevent gunicorn &&         (cd /usr/local/lib/python2.7/dist-packages/scipy/.libs; rm *; ln ../../numpy/.libs/* .) &&         rm -rf /root/.cache\n",
      " ---> Using cache\n",
      " ---> 75306258a6e8\n",
      "Step 5/18 : USER root\n",
      " ---> Using cache\n",
      " ---> d9f00b0f45e9\n",
      "Step 6/18 : ENV APACHE_SPARK_VERSION 2.3.0\n",
      " ---> Using cache\n",
      " ---> 96d98af6fb8c\n",
      "Step 7/18 : ENV HADOOP_VERSION 2.7\n",
      " ---> Using cache\n",
      " ---> 73a631fb8e7f\n",
      "Step 8/18 : RUN apt-get -y update &&     apt-get install --no-install-recommends -y openjdk-8-jre-headless ca-certificates-java &&     apt-get clean &&     rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> e1336b3e6c27\n",
      "Step 9/18 : RUN cd /tmp &&         wget -q http://apache.claz.org/spark/spark-${APACHE_SPARK_VERSION}/spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz &&         echo \"258683885383480BA01485D6C6F7DC7CFD559C1584D6CEB7A3BBCF484287F7F57272278568F16227BE46B4F92591768BA3D164420D87014A136BF66280508B46 *spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz\" | sha512sum -c - &&         tar xzf spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz -C /usr/local &&         rm spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz\n",
      " ---> Using cache\n",
      " ---> 5d05d8cfc66f\n",
      "Step 10/18 : RUN cd /usr/local && ln -s spark-${APACHE_SPARK_VERSION}-bin-hadoop${HADOOP_VERSION} spark\n",
      " ---> Using cache\n",
      " ---> f2046b056a35\n",
      "Step 11/18 : ENV SPARK_HOME /usr/local/spark\n",
      " ---> Using cache\n",
      " ---> 5a3a1ffd9092\n",
      "Step 12/18 : ENV PYTHONPATH $SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.6-src.zip\n",
      " ---> Using cache\n",
      " ---> 08edc04dfa4d\n",
      "Step 13/18 : ENV SPARK_OPTS --driver-java-options=-Xms1024M --driver-java-options=-Xmx4096M --driver-java-options=-Dlog4j.logLevel=info\n",
      " ---> Using cache\n",
      " ---> 49a5e817d958\n",
      "Step 14/18 : ENV PYTHONUNBUFFERED TRUE\n",
      " ---> Using cache\n",
      " ---> 3b1d2f208a39\n",
      "Step 15/18 : ENV PYTHONDONTWRITEBYTECODE TRUE\n",
      " ---> Using cache\n",
      " ---> 84358cf44e01\n",
      "Step 16/18 : ENV PATH \"/opt/program:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 29bc1a5a3ba9\n",
      "Step 17/18 : COPY alsriaz /opt/program\n",
      " ---> 10eb2d3f677e\n",
      "Removing intermediate container f64b77ebc069\n",
      "Step 18/18 : WORKDIR /opt/program\n",
      " ---> 02aa002f5077\n",
      "Removing intermediate container 512bd56eaa4b\n",
      "Successfully built 02aa002f5077\n",
      "Successfully tagged alsriaz:latest\n",
      "The push refers to a repository [697594570722.dkr.ecr.us-east-2.amazonaws.com/alsriaz]\n",
      "ceff0635973b: Preparing\n",
      "1494d5c5e0dc: Preparing\n",
      "8797a7b08ed4: Preparing\n",
      "6d3daf144269: Preparing\n",
      "25cde7055493: Preparing\n",
      "80019f2a992f: Preparing\n",
      "db584c622b50: Preparing\n",
      "52a7ea2bb533: Preparing\n",
      "52f389ea437e: Preparing\n",
      "88888b9b1b5b: Preparing\n",
      "a94e0d5a7c40: Preparing\n",
      "db584c622b50: Waiting\n",
      "52a7ea2bb533: Waiting\n",
      "52f389ea437e: Waiting\n",
      "88888b9b1b5b: Waiting\n",
      "a94e0d5a7c40: Waiting\n",
      "80019f2a992f: Waiting\n",
      "1494d5c5e0dc: Pushed\n",
      "ceff0635973b: Pushed\n",
      "db584c622b50: Pushed\n",
      "52a7ea2bb533: Pushed\n",
      "52f389ea437e: Pushed\n",
      "88888b9b1b5b: Pushed\n",
      "6d3daf144269: Pushed\n",
      "80019f2a992f: Pushed\n",
      "a94e0d5a7c40: Pushed\n",
      "8797a7b08ed4: Pushed\n",
      "25cde7055493: Pushed\n",
      "latest: digest: sha256:062098db2bdea1890044e335ce28c7b60efee2417a58134da4685990a7e2d9db size: 2622\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=alsriaz\n",
    "\n",
    "cd container\n",
    "\n",
    "chmod +x alsriaz/train\n",
    "chmod +x alsriaz/serve\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "# On a SageMaker Notebook Instance, the docker daemon may need to be restarted in order\n",
    "# to detect your network configuration correctly.  (This is a known issue.)\n",
    "if [ -d \"/home/ec2-user/SageMaker\" ]; then\n",
    "  sudo service docker restart\n",
    "fi\n",
    "\n",
    "docker build  -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# S3 prefix\n",
    "prefix = 'alsriaz'\n",
    "\n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "from time import gmtime, strftime\n",
    "\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "sess = sage.Session()\n",
    "\n",
    "WORK_DIRECTORY = 'data'\n",
    "\n",
    "data_location = sess.upload_data(WORK_DIRECTORY, key_prefix=prefix)\n",
    "\n",
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/alsriaz'.format(account, region)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree = sage.estimator.Estimator(image,\n",
    "                       role, 1, 'ml.c4.2xlarge',\n",
    "                       output_path=\"s3://{}/output\".format(sess.default_bucket()),\n",
    "                       sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: alsriaz-2018-03-20-14-16-58-687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........................................................\n",
      "\u001b[31mTraceback (most recent call last):\n",
      "  File \"/opt/program/train\", line 13, in <module>\n",
      "    import dill as pickle\u001b[0m\n",
      "\u001b[31mImportError: No module named dill\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error training alsriaz-2018-03-20-14-16-58-687: Failed Reason: AlgorithmError: Exit Code: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-fc33327c60ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TrainingJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Asynchronous fit not available'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll)\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc)\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'Completed'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'FailureReason'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'(No reason provided)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error training {}: {} Reason: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait_for_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error training alsriaz-2018-03-20-14-16-58-687: Failed Reason: AlgorithmError: Exit Code: 1"
     ]
    }
   ],
   "source": [
    "tree.fit(data_location)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
